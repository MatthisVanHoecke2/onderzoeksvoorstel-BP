%==============================================================================
% Template research proposal bachelor thesis
%==============================================================================

\documentclass[dutch]{hogent-article}

\usepackage{lipsum} % For blind text

\usepackage{float}
% Specify bibliography file
\addbibresource{references.bib}

% Information about the study programme, course, assignment
\studyprogramme{Professionele bachelor toegepaste informatica}
\course{Bachelorproef}
\assignmenttype{Onderzoeksvoorstel}
\academicyear{2023-2024}

% TODO (phase 1): Working title
\title{Optimalisatie van AI Integratie in Webapplicaties: Onderzoek naar AI Oplossingen en Integratietechnieken}

% TODO (phase 1): Student name and email address
\author{Matthis Van Hoecke}
\email{matthis.vanhoecke@student.hogent.be}

% TODO (phase 1): Give the link to your Github-repository here
\projectrepo{https://github.com/MatthisVanHoecke2/onderzoeksvoorstel-BP}

% Within which specialization from the final year of the study programme
% is this research situated? Choose from this list:
%
% - Mobile \& Enterprise development
% - AI \& Data Engineering
% - Functional \& Business Analysis
% - System \& Network Administrator
% - Mainframe Expert
% - If the research does not fit within one of these domains, specify it
%   yourself
%
\specialisation{Mobile \& Enterprise developer}
% Enter some keywords here that describe your topic
\keywords{Artificiële Intelligentie, Webapplicaties, Integratietechnieken}


\begin{document}

\begin{abstract}
  
  De markt van AI oplossingen groeit enorm sterk. Deze oplossingen zijn echter niet direct
bruikbaar voor eindgebruikers. Vaak moeten deze oplossingen geïntegreerd worden binnen
webapplicaties. Vandaag is dit soort van integraties nog niet vanzelfsprekend. Er komen
echter steeds meer integratieoplossingen voor handen.
  
  \setlength{\parskip}{1em}
  
  Binnen deze bachelorproef onderzochten we welke groepen van AI oplossingen er
bestaan en welke integratietechnieken we kunnen aanwenden om deze bruikbaar te maken
binnen webapplicaties. Hierbij komen termen als Langchain, Llama index, Tensorflow, Vector
databases, WebAssembly, en nog een aantal anderen om de hoek kijken. Met het resultaat van dit onderzoek
zouden architecten en developers sneller in staat moeten zijn om AI oplossingen te
integreren in bestaande en nieuwe webapplicaties.
  
 Om de haalbaarheid van de implementatie van deze technieken te onderzoeken, zal de onderzoeker een praktische aanpak nemen. Hierbij wordt een webapplicatie ontwikkeld die gebruik zal maken van de gevonden technieken in dit onderzoek.
  
  De resultaten tonen aan dat de diverse onderzochte integratietechnieken wel degelijk geïmplementeerd kunnen worden in webapplicaties voor gebruik van de eindgebruikers. 
  Aan de hand van deze vondsten kunnen we zeggen dat developers met gebruik van deze technieken, zelf artificiële Intelligentie kunnen implementeren in hun applicaties. 
  Alhoewel dit onderzoek gebruikmaakt van verschillende soorten technieken, is het belangerijk om te vermelden dat er alternatieven beschikbaar zijn die mogelijk beter passen bij de soort applicatie dat ontwikkeld wordt.

\end{abstract}

\tableofcontents

\bigskip

% TODO: Are you also taking on the Bachelor's thesis this year? Then uncomment
% the text below and adjust it as appropriate.

%\paragraph{Remark}

% I'm also taking up the bachelor's thesis this year. The content of this research proposal also serves as the subject for my bachelor thesis. My promoter is (Mr./Mrs.) X.\ Surname.


% Describe any differences and/or improvements in this document compared to your research proposal that you submitted for the Bachelor's thesis.

\section{Inleiding}%
\label{sec:Introduction}

% TODO: (phase 1) introduce your chosen topic, formulate the research question and sub-questions. What is the objective (is it S.M.A.R.T.?), what will be the result of the research (a Proof-of-Concept, a prototype, an advice, ...)? Why is it useful to research this topic?

De hoeveelheid artificiële intelligentie (AI)\linebreak groeit enorm snel, maar het toegankelijk maken van deze oplossingen voor eindgebruikers blijft een uitdaging. Een cruciale rol in het toegankelijk maken van AI wordt toegekend aan webapplicaties.
  \setlength{\parskip}{1em}
  
  Dergelijke applicaties zijn de meest gebruikte en meest toegankelijke vorm van applicaties.\linebreak
  Daarom, wanneer men spreekt over het verbeteren van de toegankelijkheid van artificiële intelligentie, staan webapplicaties hier centraal. Hoewel er al veel soorten AI-oplossingen zijn, blijft het integreren hiervan niet zo evident.
  
  In veel gevallen zal de complexiteit van integratie afhangen van hoe men de AI-oplossing wil gebruiken. Stel dat we een bedrijf hebben die een AI-klantenservicefunctionaliteit wil implementeren in hun applicatie met behulp van een Large Language Model (LLM), dat bekend staat voor zijn tekst generatie en beantwoording van vragen \autocite{Zhang2023}. In dit geval zal men de AI moeten trainen met specifieke informatie over het bedrijf. Als ervoor gekozen zou worden om een voorgetraind model te gebruiken, dan zal de AI mogelijks niet correct kunnen antwoorden op de vragen van de klant. Dit komt omdat het getraind zal zijn met meer algemene data dan met bedrijfsdata.
  
  De voortdurend evoluerende technologie introduceert continu nieuwe AI-oplossingen en integratiemogelijkheden, maar het is moeilijk om te bepalen welke het beste passen bij specifieke applicaties. 
  
  Vanuit dit idee kwam A.C.A. Group met de vraag voor dit onderzoek. Men moet de nodige AI-oplossingen en integratietechnieken kunnen identificeren en achterhalen of deze geïmplementeerd kunnen worden in bestaande en nieuwe applicaties. De uitdaging ligt in het vinden van de juiste tools die niet alleen op papier goed lijken te passen, maar die ook effectief kunnen worden toegepast in verschillende applicaties van A.C.A. Group. 
  
  Hieruit ontstaat de centrale vraag welke integratiemogelijkheden het meest geschikt zijn bij het implementeren van AI-oplossingen in een webapplicatie. In dit onderzoek gaat de auteur daarom eerst de AI-oplossingen en integratiemogelijkheden van die oplossingen identificeren aan de hand van een uitgebreide literatuurstudie,\linebreak waarin de auteur zal bepalen welke groepen de hoogste kwaliteit garanderen voor de laagst mogelijke prijs.
  
  De auteur start het onderzoek met een korte literatuurstudie, gevolgd door een toelichting op de methodologie. Vervolgens worden de resultaten van deze zaken besproken, waarna de auteur het onderzoek afsluit met een algemene conclusie.
  

\section{Literatuurstudie}%
\label{sec:literature review}
% TODO: (phase 3-4) write out the literature review and use references to authoritative professional literature where appropriate.

% Use the following commands to cite references:
% \autocite{BIBTEXKEY} -> (Author, year)
% \textcite{BIBTEXKEY} -> Author (year)

De literatuurstudie was opgedeeld in twee delen. In het eerste deel deed de auteur onderzoek naar de soorten kunstmatige intelligentie en welke daarvan hoogstwaarschijnlijk geïmplementeerd konden worden in een webapplicatie. De eerdergenoemde Large Language Model (LLM) werd hier opnieuw besproken. In het tweede deel onderzocht de auteur de integratiemogelijkheden van dergelijke AI.

De auteur begon zijn onderzoek met Natural Language Processing (NLP)-modellen, waarbij Large Language Models (LLMs) binnen deze categorie vielen. Het doel van NLP was computationele modellen te creëren voor het begrijpen en verwerken van natuurlijk taalgebruik \autocite{Bharati2002}. In de context van een webapplicatie had dit veel toepassingsmogelijkheden. Een voorbeeld van zo'n toepassing was het gebruik als zoekmachine of virtuele assistent om uitleg te geven over bepaalde gegevens.

Een ander model onder de NLP-categorie was een Recurrent Neural Network (RNN), dat werd gebruikt voor sequentievoorspelling en tijdsreeksvoorspelling en kon ook worden toegepast voor taalverwerking \autocite{IBMRNN2023}. Het verschil met LLM lag in hoe ze de data verwerkten, waar LLM beter geschikt was om contextuele data te verwerken, terwijl RNN de data in sequentie probeerde te verwerken.

Een volgende AI-oplossing die de auteur had onderzocht, was een Convolutional Neural Network (CNN), voornamelijk gebruikt voor het herkennen van foto- en videobeelden \autocite{IBMCNN2023}. Een mogelijke toepassing voor webapplicaties zou een reverse image search kunnen zijn, waarbij de AI het object in de foto analyseert en omzet in woorden.

Als laatste werden Generative Adversarial Networks (GANs) onderzocht. Het doel van deze AI is om realistische gegevens te genereren, zoals afbeeldingen, tekst, of data voor een andere AI te trainen \autocite{Goodfellow2020}. Een GAN bestaat uit twee componenten, een generator, die realistische data probeert te genereren en een discriminator die de gegenereerde data probeert te valideren als echte gegevens \autocite{Goodfellow2020}. Een bekend gebruik van GANs tegenwoordig is het genereren van deepfakes van beroemdheden. Zo kan men het laten lijken alsof een bekend figuur iets zegt wat die nooit werkelijk heeft uitgesproken.

Met de verzamelde informatie kon de auteur beginnen met de literatuurstudie naar integratiemogelijkheden. In de volgende fase van de studie zullen er een aantal van deze mogelijkheden in kaart worden gebracht, samen met een aantal andere studies die gebruik maken van dergelijke integraties. Het is belangrijk om op te merken dat sommige toepassingen ondersteuning aanbieden voor verschillende soorten AI. Dat zal een bepalend punt zijn bij het selecteren van dergelijke toepassingen.

Beginnend met NLPs, specifieker nog, Large Language Models (LLMs). Er zijn veel frameworks die LLM aanbieden, zoals OpenAI’s GPT-4, LangChain, LlamaIndex, en Tensorflow. Maar aangezien het gebruik van de GPT-4 API betalend is, in tegenstelling tot de andere frameworks, zullen we die niet toepassen in ons onderzoek. 

LangChain onderscheidt zich doordat het met meerdere LLMs tegelijk kan werken. Het kan verschillende inputs omvormen naar een output of als router dienen om specifieke inputs aan de geschikte LLM door te geven \autocite{Topsakal2023CreatingLL}. LLamaIndex daarentegen gaat de focus proberen leggen op zelfgetrainde modellen, waarbij die de mogelijkheid geeft om al bestaande gegevens zoals een API, te koppelen met de gegevens die LlamaIndex toekend \autocite{Liu2022}.

TensorFlow is een zeer uitgebreid framework die verschillende AI-oplossingen aanbiedt \autocite{TensorFlow2022}. In kader van een Language Model, kan het zowel het RNN-model als nog een aantal andere zoals het Bidirectional Encoder Representations from Transformers (BERT) model gebruiken voor taalverwerking \autocite{Chollet2015}. 

Dit laatste model verschilt van andere modellen op het gebied van richting; het is een bidirectioneel model \autocite{Devlin2018}. Dit houdt in dat de betekenis van een bepaald woord in een zin wordt afgeleid uit wat er voor en na het woord komt. Bijvoorbeeld het woord “bank” kan twee betekenissen hebben afhankelijk van de context, zoals in meubilair of financiëel instituut. Een unidirectioneel model zou het onderscheid maken aan de hand van wat er voor “bank” staat. Bijvoorbeeld in de zin “Ik haal geld van de bankrekening”, zou het model alleen het “Ik haal geld van de” gedeelte gebruiken om “bank” te onderscheiden. Een bidirectioneel model zou het gedeelte achter “bank” ook gebruiken \autocite{Devlin2018}.

Helaas kon de auteur geen frameworks vinden die zich specifiek specialiseren in RNN of GAN-modellen, maar er waren een aantal frameworks die deze wel aanbieden. De meest voorkomende frameworks waren Keras, PyTorch en opnieuw TensorFlow. Maar aangezien Keras nu deel is van TensorFlow \autocite{TensorFlow2023}, zullen die twee samen geëvalueerd worden.

Om te bepalen welk framework de beste integratieoplossing biedt, heeft de auteur een vergelijkende studie gevonden tussen PyTorch en TensorFlow. In die studie werd geconcludeerd dat over het algemeen PyTorch efficiënter en meer beginners-vriendelijk is dan TensorFlow. Dit werd aangetoond aan de hand van de nauwkeurigheid, training- en executiesnelheid van de modellen, alsook de simpliciteit van de installatie van PyTorch. Voor PyTorch moest er maar één pakket installeren en bleek 1,16\% nauwkeuriger, 25,5\% sneller getraind, en 77,7\% sneller uitgevoerd te worden dan TensorFlow \autocite{Novac2022AnalysisOT}.

Echter, aangezien IBM, een bedrijf met één van de grootste onderzoeksinstellingen in AI, ook een artikel heeft gepubliceerd over dit specifiek onderwerp, kan er nog geen keuze gemaakt worden tussen PyTorch en TensorFlow. Volgens IBM is het voordeliger om TensorFlow te gebruiken vanwege verschillende voordelen zoals eager execution, distributed processing en performantie \autocite{Madhavan2021}. Het dilemma ligt nu in het feit dat, alhoewel IBM een grote rol speelt in de ontwikkeling van AI, ze in dit artikel geen statistieke gegevens hebben teruggegeven om hun standpunten te verdedigen. Een groot voordeel van TensorFlow is echter dat Keras er als library in zit \autocite{Novac2022AnalysisOT}. 

Tijdens het onderzoek stuitte de auteur op een groot aantal studies en artikelen die Keras gebruikten, waaronder toepassingen van AI in de medische sector, zoals het voorspellen van heropnames van patiënten \autocite{Anshik2021}. Daarnaast biedt TensorFlow een JavaScript library aan, die voordeliger is voor webapplicaties \autocite{TensorFlowJS2015}.

In conclusie, kan de auteur op basis van bovenstaande gegevens aantonen dat het meest geschikte framework voor integratie van AI TensorFlow zal zijn. De uitgebreide functionaliteit van TensorFlow, gekoppeld met de verschillende AI mogelijkheden en de integratie van Keras als library, maakt het een duidelijke keuze voor webapplicatieontwikkeling. Het integreren van Large Language Models zal meer afhangen van hoe we het model willen gebruiken. In de context van een klantenservice feature, zou LlamaIndex voordeliger zijn, omdat we die makkelijker kunnen trainen met bedrijfsgegevens. Op vlak van een zoekmachine zou het BERT model van TensorFlow handiger zijn vanwege de bidirectionele functionaliteit.

\section{Methodologie}%
\label{sec:methodology}

% TODO: (phase 5) describe in detail which phases your research can be divided into, how long each phase lasts and what the concrete result of each phase is. What research technique will you use to answer each of your research questions? Do you use experiments, questionnaires, simulations for this? You also describe which tools you intend to use or develop for this. Include a flowchart or Gantt-chart to illustrate your planning.

Het doel van dit onderdeel is om te beschrijven hoe de auteur zijn onderzoek naar de optimalisatie van AI-integratie in webapplicaties zal uitvoeren. De auteur zal onderzoeken of de gekozen integratiemethode haalbaar is in een werkelijke webapplicatie en of deze methode geen vertraging veroorzaakt in de applicatie.

In de eerste fase zal gedurende een periode van drie weken data worden verzameld aan de hand van een uitgebreid literatuuronderzoek. Dit onderzoek zal de vorige literatuurstudie uitbreiden met meer uitleg over de genoemde\linebreak AI-oplossingen, samen met andere nog niet genoemde oplossingen en hun integratietechnieken die in een webapplicatie zouden kunnen worden geïntegreerd.

Zodra de auteur een lange lijst heeft van toepasbare artificiële intelligentie, zal hij twee weken besteden aan het verfijnen en beoordelen van de lange lijst om te bepalen welke het meest bruikbaar zal zijn voor dit onderzoek.

Als resultaat van het verfijnen, zal de korte lijst worden gegroepeerd op basis van het MoSCoW-principe \autocite{Nordenstam2014}. Deze lijst zal de basis vormen voor de volgende fase, de Proof-of-Concept.

In deze fase zal de auteur gedurende twee weken één van de meest veelbelovende\linebreak AI-oplossingen en integratietechnieken toepassen in een kleine webapplicatie. Het doel van deze fase is om te bewijzen dat een artificiële intelligentie model wel degelijk toegepast kan worden in een webapplicatie aan de hand van de gekozen integratietechniek.

In de laatste fase zal een conclusie worden gemaakt samen met toekomstige aanbevelingen, gebaseerd op de resultaten van de Proof-of-conc\-ept, waaruit we drie mogelijke resultaten kunnen verwachten: de integratie verliep vlot en de AI veroorzaakt geen vertraging van de applicatie, de integratie was uitdagend en de AI veroorzaakt minimale vertraging, of de integratie was zeer moeizaam en de AI veroorzaakt veel vertraging van de webapplicatie. De toekomstige aanbeveling zal gebaseerd zijn op dit resultaat.

\section{Te verwachten resultaten}%
\label{sec:expected-results}

% TODO: (phase 6) describe what you expect from your research and why (e.g. according to your literature search software package A is the most used and you think it will be most suitable for this case). Of course you can't look into the future and you can't rule out alternative possibilities. In practice, it often happens that research leads to surprising results, which makes the process even more interesting!

Het doel van deze studie is om de optimale integratie van AI uit te zoeken aan de hand van een Proof-of-Concept. De auteur zal de eenvoud van implementatie, en de performantie van de AI analyseren om tot een conclusie te komen. De hypothese is dat de implementatie vlot verloopt en de AI geen of minimale vertragingen veroorzaakt op de applicatie.

De hypothese zal worden getest door het gebruik van statistische testen, zoals t-tests of chi-square tests, om te bepalen hoe groot het verschil is tussen de performantie van een applicatie zonder AI en een applicatie met AI. Het onderzoek benadrukt dat er een al dan niet te groot, verschil zal zijn. De statistische analyse zal dit idee verifiëren of weerleggen. Als de resultaten demonstreren dat het gebruik van AI een kleine of middelmatige impact heeft op de performantie van een webapplicatie, zal de implementatie van AI in webapplicaties aanbevolen worden voor andere ontwikkelaars.



\section{Discussie, conclusie}%
\label{sec:discussion-conclusion}
In conclusion, the study has demonstrated that AI and ML algorithms can analyze large data sets to detect depression based on linguistic, multimodal, and neural network methods. These algorithms can be trained to recognize depression symptoms based on predefined indicator variables. This suggests that behavioural analysis using AI models can be a useful tool for mental health screening, offering more speed and accuracy.

However, the study also highlights the need for human expertise to verify and interpret AI results. While AI analysis shows promise in detecting disorders, human diagnosis remains crucial for personalized and comprehensive assessments. The cooperation between humans and artificial intelligence systems can enhance data analysis and improve mental health screening. This cooperation will open up new possibilities for AI in mental healthcare.

Further research and validation of AI-based methods in mental health screening will help promote effective and inclusive practices.



%------------------------------------------------------------------------------
% Bibliography
%------------------------------------------------------------------------------
% TODO: (phase 4) the referenced works must be in a BibTeX file references.bib.
% Use JabRef to edit the bibliography file.

\printbibliography[heading=bibintoc]

\end{document}